# üå¨Ô∏è Pr√©vision √âolienne Hybride : Transformer Physics-Informed

![Python](https://img.shields.io/badge/Python-3.8%2B-blue?style=flat-square)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0%2B-orange?style=flat-square)
![License](https://img.shields.io/badge/License-MIT-green?style=flat-square)
![Status](https://img.shields.io/badge/Status-Research_Prototype-purple?style=flat-square)

> **R√©sum√© Ex√©cutif** : Ce projet impl√©mente une architecture **Transformer** novatrice pour la pr√©vision de production √©olienne √† court terme (24h). Il se distingue par une approche **hybride (PIML - Physics-Informed Machine Learning)** qui int√®gre explicitement les lois a√©rodynamiques (Loi de Betz) et une fonction de co√ªt sp√©cialis√©e (**Ramp Loss**) pour anticiper les variations brutales de puissance.

---

## üéØ Fonctionnalit√©s Cl√©s

* **Architecture Transformer :** M√©canisme de *Self-Attention* capturant les d√©pendances temporelles longues (+19.2% de gain MAE vs LSTM).
* **Physics-Guided Feature Engineering :** Injection d'une courbe de puissance th√©orique ($P_{theo}$) calcul√©e par r√©gression logistique (NLLS).
* **Ramp Loss ($\mathcal{L}_{ramp}$) :** Fonction de perte hybride p√©nalisant l'erreur de d√©riv√©e pour la d√©tection de rampes.
* **Quantification d'Incertitude :** Intervalles de confiance √† 95% via *Monte Carlo Dropout*.

---

## üìä 1. Analyse Exploratoire des Donn√©es (EDA)

Avant toute mod√©lisation, une analyse approfondie des donn√©es SCADA a permis de comprendre la dynamique du site.

### Distribution et Corr√©lations
La matrice de corr√©lation confirme la relation physique forte entre la vitesse du vent et la puissance ($r=0.93$), tandis que la rose des vents r√©v√®le les directions dominantes du flux.

| Rose des Vents | Matrice de Corr√©lation |
| :---: | :---: |
| ![Rose des Vents](plots/plot_wind_rose.png) | ![Matrice de Corr√©lation](plots/plot_correlation.png) |
| *Direction dominante Nord-Est* | *Forte d√©pendance $P \propto v^3$* |

---

## üß™ 2. M√©thodologie "Physics-Informed"

### Le "Capteur Virtuel" (NLLS)
Plut√¥t que de laisser le mod√®le apprendre la relation Vent/Puissance √† partir de z√©ro (ce qui n√©cessite √©norm√©ment de donn√©es), nous pr√©-calculons une courbe th√©orique id√©ale. Nous utilisons une r√©gression logistique g√©n√©ralis√©e (Non-Linear Least Squares) ajust√©e sur les donn√©es filtr√©es.

$$P_{theo}(v) = \frac{P_{max}}{1 + e^{-k(v - v_{center})}}$$

![Courbe de Puissance Physique](plots/plot_power_curve.png)
> **Figure 1** : La courbe rouge ($P_{theo}$) agit comme un "tuteur" pour le r√©seau de neurones, filtrant le bruit stochastique des donn√©es brutes (nuage noir).

---

## üìà 3. Dynamique d'Apprentissage

Le comparatif ci-dessous montre la sup√©riorit√© de la convergence du Transformer par rapport au LSTM. Alors que le LSTM tend √† sur-apprendre (√©cart grandissant entre Train/Val), le Transformer maintient une g√©n√©ralisation robuste gr√¢ce au m√©canisme d'attention.

![Courbes d'apprentissage](plots/loss_comparison.png)

---

## üèÜ 4. R√©sultats et Performance

Les mod√®les ont √©t√© √©valu√©s sur un jeu de test strictement isol√© (10% des donn√©es finales).

| Mod√®le | MAE (Normalis√©) | MAE (R√©el) | Gain vs Baseline |
| :--- | :---: | :---: | :---: |
| **Persistance** | 0.0312 | ~56 kW | - |
| **LSTM** | 0.0229 | ~41 kW | +26.6% |
| **Transformer (Ours)** | **0.0185** | **~33 kW** | **+40.7%** |

### Benchmark Visuel (Transformer vs LSTM)
Le graphique ci-dessous illustre un √©v√©nement critique de "Rampe" (chute brutale de vent).
![Benchmark Architecture](plots/plot_benchmark.png)
> **Observation** : Le Transformer (rouge) anticipe la chute avec une latence quasi-nulle, contrairement au LSTM (bleu) qui pr√©sente un retard de phase caract√©ristique ("Lag") de 20-30 minutes.

### Exemple de Pr√©vision sur 24h
![Forecast Sample](plots/plot_forecast.png)

### Quantification de l'Incertitude
Gr√¢ce au Monte Carlo Dropout (100 passes stochastiques), nous estimons la fiabilit√© de la pr√©diction.
![Uncertainty Quantification](plots/plot_uncertainty.png)
> **Analyse** : La zone rouge repr√©sente l'intervalle de confiance √† 95%. On note que l'incertitude augmente logiquement lors des transitions de r√©gime (chute brutale vers le pas 130).

---

## üîç 5. Interpr√©tabilit√© (XAI)

Pourquoi le mod√®le est-il performant ? Nous avons utilis√© l'importance par permutation pour le savoir.

### Importance des Features
![Feature Importance](plots/plot_importance.png)
> **Validation Physique** : La variable `Theoretical_Curve` est la 2√®me plus importante (26.8%). Cela prouve que le mod√®le s'appuie activement sur la loi physique inject√©e pour corriger ses pr√©visions.

### Analyse des R√©sidus
![Distribution des Erreurs](plots/plot_residuals.png)
La distribution quasi-gaussienne centr√©e en 0 indique que le mod√®le est non-biais√© (pas de sous-estimation ou surestimation syst√©matique).

---

## ‚öôÔ∏è Installation et Reproduction

```bash
# 1. Cloner le d√©p√¥t
git clone [https://github.com/Thedarkiin/physics-informed-wind-transformer.git](https://github.com/Thedarkiin/physics-informed-wind-transformer.git)
cd wind-turbine

# 2. Installer les d√©pendances
pip install -r requirements.txt

# 3. Lancer l'entra√Ænement
python src/train.py --epochs 10 --batch_size 32

# 4. G√©n√©rer les graphiques d'analyse
python src/explain.py